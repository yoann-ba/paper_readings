https://arxiv.org/abs/1706.03762

- original Transformer paper 2017, Google Brain [1706.03762] Attention Is All You Need https://arxiv.org/abs/1706.03762
- original Vision Transformer paper 2020, Google Brain [2010.11929] An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale https://arxiv.org/abs/2010.11929
- third party overview article of the Vision Transformer Overview Of Vision Transformers Is All You Need | by Mustafa Gültekin | Sep, 2022 | Towards AI https://pub.towardsai.net/overview-of-vision-transformers-is-all-you-need-88727438ff8d

# Transformers Original Paper

Propose a new simple network architecture, the Transformer, based solely on attention mechanisms.

Replaces the Encoder > Attention Heads > Decoder pipeline that was State of the Art, based on RNNs or CNNs.

Replaces the LSTM-RNN as the default architecture for NLP and competes with CNNs for Computer Vision.

Can be parallelised in areas where the RNNs couldn’t be.